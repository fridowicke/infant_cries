{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG2HaZjNp495"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we carry out the Transfer Learning Experiments.\n",
        "The other notebooks, as well as the thesis can be found at https://github.com/fridowicke/infant_cries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYPAEfNdqFCQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ty0QAjULmEAt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-06 10:56:32.225420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from google.colab import drive\n",
        "import json\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2jgVdlFnEOw"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ebqeLeCiUd"
      },
      "source": [
        "## Mount the Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFW5Z6M4bJw",
        "outputId": "b3737757-3e8c-49d5-c91c-c9101cc6bf02"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfje4TgtJosG"
      },
      "source": [
        "## Save / Load Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqAF_UYRJs5o"
      },
      "outputs": [],
      "source": [
        "#We use json to save the spectrograms and f0s of the produced data in order to avoid computing them every time we use the notebook.\n",
        "#Helper functions\n",
        "def save(data, filename):\n",
        "    if type(data) is np.ndarray:\n",
        "      data = data.tolist()\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "        \n",
        "def load(filename):\n",
        "    with open(filename) as data:\n",
        "        x = json.load(data)\n",
        "    return np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLoWosHc9ujn"
      },
      "outputs": [],
      "source": [
        "#Load the Data\n",
        "specs_train = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_train.json\")\n",
        "y_train = load(\"/content/drive/My Drive/infant_cries/data_js_final/y_train.json\")\n",
        "specs_dev_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_ger.json\")\n",
        "specs_dev_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_jap.json\")\n",
        "specs_test_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_ger.json\")\n",
        "specs_test_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_jap.json\")\n",
        "specs_eval = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_eval.json\")\n",
        "X_dev_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_ger.json\")\n",
        "X_dev_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_jap.json\")\n",
        "X_test_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_ger.json\")\n",
        "X_test_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_jap.json\")\n",
        "X_eval = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_eval.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogzzbEfSKVVn"
      },
      "source": [
        "## Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyXExz7TPo13"
      },
      "outputs": [],
      "source": [
        "#Size of the Dataset\n",
        "n, height, width = specs_train.shape\n",
        "n_dev_ger = specs_dev_ger.shape[0]\n",
        "n_dev_jap = specs_dev_jap.shape[0]\n",
        "n_test_ger = specs_test_ger.shape[0]\n",
        "n_test_jap = specs_test_jap.shape[0]\n",
        "n_eval = specs_eval.shape[0]\n",
        "\n",
        "#Create the ys for dev and test set\n",
        "y_dev_ger = np.zeros(n_dev_ger)\n",
        "y_dev_jap = np.ones(n_dev_jap)\n",
        "y_test_ger = np.zeros(n_test_ger)\n",
        "y_test_jap = np.ones(n_test_jap)\n",
        "\n",
        "#Reshape spectrograms for train, dev, test, eval\n",
        "specs_train = specs_train.reshape([n,height,width,1])\n",
        "specs_dev_ger = specs_dev_ger.reshape([n_dev_ger,height,width,1])\n",
        "specs_dev_jap = specs_dev_jap.reshape([n_dev_jap,height,width,1])\n",
        "specs_test_ger = specs_test_ger.reshape([n_test_ger,height,width,1])\n",
        "specs_test_jap = specs_test_jap.reshape([n_test_jap,height,width,1])\n",
        "specs_eval = specs_eval.reshape([n_eval,height,width,1])\n",
        "\n",
        "#Create mixed dev set\n",
        "specs_dev = np.zeros((2*n_dev_jap, height, width, 1))\n",
        "specs_dev[:n_dev_jap] = specs_dev_jap\n",
        "specs_dev[n_dev_jap:] = np.vstack((specs_dev_ger,specs_dev_ger,specs_dev_ger,specs_dev_ger))[:n_dev_jap]\n",
        "y_dev = np.zeros(2*n_dev_jap)\n",
        "y_dev[:n_dev_jap] = 1\n",
        "\n",
        "#Create mixed test set\n",
        "specs_test = np.zeros((2*n_test_jap, height, width, 1))\n",
        "specs_test[:n_test_jap] = specs_test_jap\n",
        "specs_test[n_test_jap:] = np.vstack((specs_test_ger,specs_test_ger,specs_test_ger,specs_test_ger))[:n_test_jap]\n",
        "y_test = np.zeros(2*n_test_jap)\n",
        "y_test[:n_test_jap] = 1\n",
        "\n",
        "#Create the eval set\n",
        "y_eval = np.zeros(n_eval)\n",
        "\n",
        "#Set the Class Names\n",
        "class_names = [\"German\", \"Japanese\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HwAX5zr9C2ff"
      },
      "source": [
        "# Pretrained TRILL"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K2FLZagoFyDv"
      },
      "source": [
        "## Create Dataset and function to pretrain TRILL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01VS9P7ADdLA"
      },
      "outputs": [],
      "source": [
        "specs_train_resnet = tf.tile(specs_train, [1,1,1,3])\n",
        "specs_dev_resnet = tf.tile(specs_dev, [1,1,1,3])\n",
        "specs_dev_ger_resnet = tf.tile(specs_dev_ger, [1,1,1,3])\n",
        "specs_dev_jap_resnet = tf.tile(specs_dev_jap, [1,1,1,3])\n",
        "\n",
        "specs_test_resnet = tf.tile(specs_test, [1,1,1,3])\n",
        "specs_test_ger_resnet = tf.tile(specs_test_ger, [1,1,1,3])\n",
        "specs_test_jap_resnet = tf.tile(specs_test_jap, [1,1,1,3])\n",
        "\n",
        "specs_eval_resnet = tf.tile(specs_eval, [1,1,1,3])\n",
        "input_shape  = (height, width,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DWRZn2tfF5Cn"
      },
      "outputs": [],
      "source": [
        "def pretrain_trill(model = 'https://tfhub.dev/google/trillsson5/1'):\n",
        "  input = layers.Input(shape=(None,))\n",
        "  m = hub.KerasLayer(model)\n",
        "\n",
        "  # NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
        "  # the shape [batch size, time].\n",
        "  # audio_samples = tf.zeros([3, 64000])\n",
        "\n",
        "  embeddings = m(input)['embedding']\n",
        "\n",
        "  x = layers.Flatten()(embeddings)\n",
        "  x = layers.Dense(1000, activation='relu')(x)\n",
        "  predictions = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "  trill_pretrained = tf.keras.Model(inputs = m.input, outputs = predictions)\n",
        "  trill_pretrained.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "  return trill_pretrained\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-06 11:06:28.318529: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n",
            "2023-02-06 11:06:28.318736: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n",
            "2023-02-06 11:06:28.318867: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n"
          ]
        }
      ],
      "source": [
        "model = pretrain_trill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 21s 21s/step\n",
            "[[0.99406517 0.00593482]\n",
            " [0.9941636  0.00583639]\n",
            " [0.9939255  0.00607455]]\n"
          ]
        }
      ],
      "source": [
        "out = model.predict(tf.ones([3, 64000]))\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-y7ysCDF5m2"
      },
      "source": [
        "## Determine ideal number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lVEX9O9nM97H",
        "outputId": "4989322c-e323-4502-e4c6-d607bc425004"
      },
      "outputs": [],
      "source": [
        "trill_pretrained = pretrain_trill()\n",
        "dev_accs=np.zeros(40)\n",
        "for idx1 in range(5):\n",
        "  resnet_prettrill = pretrain_trill()\n",
        "  for idx in range(40):\n",
        "    if idx%10==0:\n",
        "      print(idx1, idx)\n",
        "    history = trill_pretrained.fit(specs_train_trill, y_train, batch_size=64, epochs=1, verbose=0)\n",
        "    _, train_acc = trill_pretrained.evaluate(specs_train_trill, y_train, verbose=0)\n",
        "    _, dev_acc = trill_pretrained.evaluate(specs_dev_resnet, y_dev, verbose=0)\n",
        "    dev_accs[idx]= dev_accs[idx]+dev_acc\n",
        "\n",
        "dev_accs = dev_accs/5\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(np.arange(40), dev_accs, color='orange', label='Accuracy on the Development Set')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuarcy')\n",
        "plt.hlines(np.max(dev_accs), 0, np.argmax(dev_accs), colors='grey', linestyles='dashed')\n",
        "plt.vlines(np.argmax(dev_accs), np.min(dev_accs), np.max(dev_accs), colors='grey', linestyles='dashed')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "num_epochs = np.argmax(dev_accs)+1\n",
        "print(num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBv6LapxF8Zu"
      },
      "source": [
        "## Test Pretrained ResNet with optimal Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN9Tmxa4EvSz",
        "outputId": "7e778b96-23d1-444d-efa2-278b168f32cb"
      },
      "outputs": [],
      "source": [
        "accs_dev_ResNet  = []\n",
        "accs_test_ResNet = []\n",
        "fscore_eval_ResNet   = []\n",
        "\n",
        "for idx in range(100):\n",
        "  print(idx)\n",
        "  ResNet = pretrain_resnet()\n",
        "  ResNet.fit(specs_train_resnet, y_train, batch_size=64, epochs=num_epochs, verbose=0)\n",
        "  _, acc_dev_ger = ResNet.evaluate(specs_dev_ger_resnet, y_dev_ger, verbose=0)\n",
        "  _, acc_dev_jap = ResNet.evaluate(specs_dev_jap_resnet, y_dev_jap, verbose=0)\n",
        "  _, acc_test_ger = ResNet.evaluate(specs_test_ger_resnet, y_test_ger, verbose=0)\n",
        "  _, acc_test_jap = ResNet.evaluate(specs_test_jap_resnet, y_test_jap, verbose=0)\n",
        "  _, acc_eval = ResNet.evaluate(specs_eval_resnet, y_eval, verbose=0)\n",
        "  acc_dev  = (acc_dev_ger+acc_dev_jap)/2\n",
        "  acc_test = (acc_test_ger+acc_test_jap)/2\n",
        "  accs_dev_ResNet.append(acc_dev)\n",
        "  accs_test_ResNet.append(acc_test)\n",
        "  fscore_eval_ResNet.append(2*(acc_eval)/(1+acc_eval))\n",
        "\n",
        "save(accs_dev_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/accs_dev_ResNet.json\")\n",
        "save(accs_test_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/accs_test_ResNet.json\")\n",
        "save(fscore_eval_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/fscore_eval_ResNet.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm2Kt051bVpm"
      },
      "outputs": [],
      "source": [
        "accs_dev_ResNet      = load(\"/content/drive/My Drive/infant_cries/data_js_final/accs_dev_ResNet.json\")\n",
        "accs_test_ResNet     = load (\"/content/drive/My Drive/infant_cries/data_js_final/accs_test_ResNet.json\")\n",
        "fscore_eval_ResNet   = load(\"/content/drive/My Drive/infant_cries/data_js_final/fscore_eval_ResNet.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "o4HeXiXUbi5g",
        "outputId": "23cbaa32-f6b9-4232-e12b-79b7225ee588"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(accs_dev_ResNet)}, Min:{np.min(accs_dev_ResNet)}, Max:{np.max(accs_dev_ResNet)}\")\n",
        "print(f\"50th percentile. {np.percentile(accs_dev_ResNet, 50)}\")\n",
        "plt.hist(accs_dev_ResNet)\n",
        "plt.axvline(np.mean(accs_dev_ResNet), color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UsRoqO-rcA75",
        "outputId": "8b24bd47-53e7-4b3f-919c-7d81473c696c"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(accs_test_ResNet)}, Min:{np.min(accs_test_ResNet)}, Max:{np.max(accs_test_ResNet)}\")\n",
        "plt.hist(accs_test_ResNet)\n",
        "plt.axvline(np.mean(accs_test_ResNet), color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Q1DrgFJ6cKY5",
        "outputId": "263f70d5-b231-4874-9138-aaaafff6d62a"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(fscore_eval_ResNet)}, Min:{np.min(fscore_eval_ResNet)}, Max:{np.max(fscore_eval_ResNet)}\")\n",
        "plt.hist(fscore_eval_ResNet)\n",
        "plt.axvline(np.mean(fscore_eval_ResNet), color='red')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c339f14f070da8202a0a6b354db3eadd1601ac9870fe85de691374b6daa73d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

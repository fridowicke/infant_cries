{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG2HaZjNp495"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we carry out the Transfer Learning Experiments.\n",
        "The other notebooks, as well as the thesis can be found at https://github.com/fridowicke/infant_cries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYPAEfNdqFCQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ty0QAjULmEAt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from google.colab import drive\n",
        "import json\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2jgVdlFnEOw"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ebqeLeCiUd"
      },
      "source": [
        "## Mount the Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFW5Z6M4bJw",
        "outputId": "b3737757-3e8c-49d5-c91c-c9101cc6bf02"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfje4TgtJosG"
      },
      "source": [
        "## Save / Load Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqAF_UYRJs5o"
      },
      "outputs": [],
      "source": [
        "#We use json to save the spectrograms and f0s of the produced data in order to avoid computing them every time we use the notebook.\n",
        "#Helper functions\n",
        "def save(data, filename):\n",
        "    if type(data) is np.ndarray:\n",
        "      data = data.tolist()\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "        \n",
        "def load(filename):\n",
        "    with open(filename) as data:\n",
        "        x = json.load(data)\n",
        "    return np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLoWosHc9ujn"
      },
      "outputs": [],
      "source": [
        "#Load the Data\n",
        "specs_train = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_train.json\")\n",
        "y_train = load(\"/content/drive/My Drive/infant_cries/data_js_final/y_train.json\")\n",
        "specs_dev_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_ger.json\")\n",
        "specs_dev_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_jap.json\")\n",
        "specs_test_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_ger.json\")\n",
        "specs_test_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_dev_jap.json\")\n",
        "specs_eval = load(\"/content/drive/My Drive/infant_cries/data_js_final/specs_eval.json\")\n",
        "X_dev_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_ger.json\")\n",
        "X_dev_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_jap.json\")\n",
        "X_test_ger = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_ger.json\")\n",
        "X_test_jap = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_dev_jap.json\")\n",
        "X_eval = load(\"/content/drive/My Drive/infant_cries/data_js_final/X_eval.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogzzbEfSKVVn"
      },
      "source": [
        "## Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyXExz7TPo13"
      },
      "outputs": [],
      "source": [
        "#Size of the Dataset\n",
        "n, height, width = specs_train.shape\n",
        "n_dev_ger = specs_dev_ger.shape[0]\n",
        "n_dev_jap = specs_dev_jap.shape[0]\n",
        "n_test_ger = specs_test_ger.shape[0]\n",
        "n_test_jap = specs_test_jap.shape[0]\n",
        "n_eval = specs_eval.shape[0]\n",
        "\n",
        "#Create the ys for dev and test set\n",
        "y_dev_ger = np.zeros(n_dev_ger)\n",
        "y_dev_jap = np.ones(n_dev_jap)\n",
        "y_test_ger = np.zeros(n_test_ger)\n",
        "y_test_jap = np.ones(n_test_jap)\n",
        "\n",
        "#Reshape spectrograms for train, dev, test, eval\n",
        "specs_train = specs_train.reshape([n,height,width,1])\n",
        "specs_dev_ger = specs_dev_ger.reshape([n_dev_ger,height,width,1])\n",
        "specs_dev_jap = specs_dev_jap.reshape([n_dev_jap,height,width,1])\n",
        "specs_test_ger = specs_test_ger.reshape([n_test_ger,height,width,1])\n",
        "specs_test_jap = specs_test_jap.reshape([n_test_jap,height,width,1])\n",
        "specs_eval = specs_eval.reshape([n_eval,height,width,1])\n",
        "\n",
        "#Create mixed dev set\n",
        "specs_dev = np.zeros((2*n_dev_jap, height, width, 1))\n",
        "specs_dev[:n_dev_jap] = specs_dev_jap\n",
        "specs_dev[n_dev_jap:] = np.vstack((specs_dev_ger,specs_dev_ger,specs_dev_ger,specs_dev_ger))[:n_dev_jap]\n",
        "y_dev = np.zeros(2*n_dev_jap)\n",
        "y_dev[:n_dev_jap] = 1\n",
        "\n",
        "#Create mixed test set\n",
        "specs_test = np.zeros((2*n_test_jap, height, width, 1))\n",
        "specs_test[:n_test_jap] = specs_test_jap\n",
        "specs_test[n_test_jap:] = np.vstack((specs_test_ger,specs_test_ger,specs_test_ger,specs_test_ger))[:n_test_jap]\n",
        "y_test = np.zeros(2*n_test_jap)\n",
        "y_test[:n_test_jap] = 1\n",
        "\n",
        "#Create the eval set\n",
        "y_eval = np.zeros(n_eval)\n",
        "\n",
        "#Set the Class Names\n",
        "class_names = [\"German\", \"Japanese\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HwAX5zr9C2ff"
      },
      "source": [
        "# Pretrained TRILL"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K2FLZagoFyDv"
      },
      "source": [
        "## Create Dataset and function to pretrain TRILL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01VS9P7ADdLA"
      },
      "outputs": [],
      "source": [
        "specs_train_resnet = tf.tile(specs_train, [1,1,1,3])\n",
        "specs_dev_resnet = tf.tile(specs_dev, [1,1,1,3])\n",
        "specs_dev_ger_resnet = tf.tile(specs_dev_ger, [1,1,1,3])\n",
        "specs_dev_jap_resnet = tf.tile(specs_dev_jap, [1,1,1,3])\n",
        "\n",
        "specs_test_resnet = tf.tile(specs_test, [1,1,1,3])\n",
        "specs_test_ger_resnet = tf.tile(specs_test_ger, [1,1,1,3])\n",
        "specs_test_jap_resnet = tf.tile(specs_test_jap, [1,1,1,3])\n",
        "\n",
        "specs_eval_resnet = tf.tile(specs_eval, [1,1,1,3])\n",
        "input_shape  = (height, width,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DWRZn2tfF5Cn"
      },
      "outputs": [],
      "source": [
        "def pretrain_trill():\n",
        "  input = layers.Input(shape=(16000))\n",
        "  m = hub.KerasLayer('https://tfhub.dev/google/trillsson5/1')\n",
        "  # NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
        "  # the shape [batch size, time].\n",
        "  # audio_samples = tf.zeros([3, 64000])\n",
        "\n",
        "  embeddings = m(input)['embedding']\n",
        "\n",
        "  x = layers.Flatten()(embeddings)\n",
        "  x = layers.Dense(1000, activation='relu')(x)\n",
        "  predictions = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "  trill_pretrained = tf.keras.Model(inputs = m.input, outputs = predictions)\n",
        "  trill_pretrained.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "  return trill_pretrained\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-04 11:38:34.561256: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n",
            "2023-02-04 11:38:34.561601: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n",
            "2023-02-04 11:38:34.561735: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"keras_layer_4\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/tim/Documents/dfki/shared_projects/infant_cries/venv/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * <tf.Tensor 'inputs:0' shape=(None, None, 200) dtype=float32>\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='audio_samples')\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='audio_samples')\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_4\" (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, None, 200), dtype=float32)\n  • training=None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m pretrain_trill()\n",
            "Cell \u001b[0;32mIn[17], line 8\u001b[0m, in \u001b[0;36mpretrain_trill\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m m \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(\u001b[39m'\u001b[39m\u001b[39mhttps://tfhub.dev/google/trillsson5/1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# the shape [batch size, time].\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# audio_samples = tf.zeros([3, 64000])\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m embeddings \u001b[39m=\u001b[39m m(\u001b[39minput\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mFlatten()(embeddings)\n\u001b[1;32m     11\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m1000\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x)\n",
            "File \u001b[0;32m~/Documents/dfki/shared_projects/infant_cries/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filecleoqx8i.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     72\u001b[0m     result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope))), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope)))), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     73\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_6\u001b[39m():\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m (result,)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filecleoqx8i.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(smart_cond)\u001b[39m.\u001b[39;49msmart_cond, (ag__\u001b[39m.\u001b[39;49mld(training), ag__\u001b[39m.\u001b[39;49mautograph_artifact((\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope))), ag__\u001b[39m.\u001b[39;49mautograph_artifact((\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope)))), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filecleoqx8i.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope))), ag__\u001b[39m.\u001b[39mautograph_artifact((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope)))), \u001b[39mNone\u001b[39;00m, fscope)\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_4\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/tim/Documents/dfki/shared_projects/infant_cries/venv/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * <tf.Tensor 'inputs:0' shape=(None, None, 200) dtype=float32>\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='audio_samples')\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * TensorSpec(shape=(None, None), dtype=tf.float32, name='audio_samples')\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_4\" (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, None, 200), dtype=float32)\n  • training=None"
          ]
        }
      ],
      "source": [
        "model = pretrain_trill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-y7ysCDF5m2"
      },
      "source": [
        "## Determine ideal number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lVEX9O9nM97H",
        "outputId": "4989322c-e323-4502-e4c6-d607bc425004"
      },
      "outputs": [],
      "source": [
        "resnet_pretrained = pretrain_resnet()\n",
        "dev_accs=np.zeros(40)\n",
        "for idx1 in range(5):\n",
        "  resnet_pretrained = pretrain_resnet()\n",
        "  for idx in range(40):\n",
        "    if idx%10==0:\n",
        "      print(idx1, idx)\n",
        "    history = resnet_pretrained.fit(specs_train_resnet, y_train, batch_size=64, epochs=1, verbose=0)\n",
        "    _, train_acc = resnet_pretrained.evaluate(specs_train_resnet, y_train, verbose=0)\n",
        "    _, dev_acc = resnet_pretrained.evaluate(specs_dev_resnet, y_dev, verbose=0)\n",
        "    dev_accs[idx]= dev_accs[idx]+dev_acc\n",
        "\n",
        "dev_accs = dev_accs/5\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(np.arange(40), dev_accs, color='orange', label='Accuracy on the Development Set')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuarcy')\n",
        "plt.hlines(np.max(dev_accs), 0, np.argmax(dev_accs), colors='grey', linestyles='dashed')\n",
        "plt.vlines(np.argmax(dev_accs), np.min(dev_accs), np.max(dev_accs), colors='grey', linestyles='dashed')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "num_epochs = np.argmax(dev_accs)+1\n",
        "print(num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBv6LapxF8Zu"
      },
      "source": [
        "## Test Pretrained ResNet with optimal Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN9Tmxa4EvSz",
        "outputId": "7e778b96-23d1-444d-efa2-278b168f32cb"
      },
      "outputs": [],
      "source": [
        "accs_dev_ResNet  = []\n",
        "accs_test_ResNet = []\n",
        "fscore_eval_ResNet   = []\n",
        "\n",
        "for idx in range(100):\n",
        "  print(idx)\n",
        "  ResNet = pretrain_resnet()\n",
        "  ResNet.fit(specs_train_resnet, y_train, batch_size=64, epochs=num_epochs, verbose=0)\n",
        "  _, acc_dev_ger = ResNet.evaluate(specs_dev_ger_resnet, y_dev_ger, verbose=0)\n",
        "  _, acc_dev_jap = ResNet.evaluate(specs_dev_jap_resnet, y_dev_jap, verbose=0)\n",
        "  _, acc_test_ger = ResNet.evaluate(specs_test_ger_resnet, y_test_ger, verbose=0)\n",
        "  _, acc_test_jap = ResNet.evaluate(specs_test_jap_resnet, y_test_jap, verbose=0)\n",
        "  _, acc_eval = ResNet.evaluate(specs_eval_resnet, y_eval, verbose=0)\n",
        "  acc_dev  = (acc_dev_ger+acc_dev_jap)/2\n",
        "  acc_test = (acc_test_ger+acc_test_jap)/2\n",
        "  accs_dev_ResNet.append(acc_dev)\n",
        "  accs_test_ResNet.append(acc_test)\n",
        "  fscore_eval_ResNet.append(2*(acc_eval)/(1+acc_eval))\n",
        "\n",
        "save(accs_dev_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/accs_dev_ResNet.json\")\n",
        "save(accs_test_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/accs_test_ResNet.json\")\n",
        "save(fscore_eval_ResNet,\"/content/drive/My Drive/infant_cries/data_js_final/fscore_eval_ResNet.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm2Kt051bVpm"
      },
      "outputs": [],
      "source": [
        "accs_dev_ResNet      = load(\"/content/drive/My Drive/infant_cries/data_js_final/accs_dev_ResNet.json\")\n",
        "accs_test_ResNet     = load (\"/content/drive/My Drive/infant_cries/data_js_final/accs_test_ResNet.json\")\n",
        "fscore_eval_ResNet   = load(\"/content/drive/My Drive/infant_cries/data_js_final/fscore_eval_ResNet.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "o4HeXiXUbi5g",
        "outputId": "23cbaa32-f6b9-4232-e12b-79b7225ee588"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(accs_dev_ResNet)}, Min:{np.min(accs_dev_ResNet)}, Max:{np.max(accs_dev_ResNet)}\")\n",
        "print(f\"50th percentile. {np.percentile(accs_dev_ResNet, 50)}\")\n",
        "plt.hist(accs_dev_ResNet)\n",
        "plt.axvline(np.mean(accs_dev_ResNet), color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UsRoqO-rcA75",
        "outputId": "8b24bd47-53e7-4b3f-919c-7d81473c696c"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(accs_test_ResNet)}, Min:{np.min(accs_test_ResNet)}, Max:{np.max(accs_test_ResNet)}\")\n",
        "plt.hist(accs_test_ResNet)\n",
        "plt.axvline(np.mean(accs_test_ResNet), color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Q1DrgFJ6cKY5",
        "outputId": "263f70d5-b231-4874-9138-aaaafff6d62a"
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:{np.mean(fscore_eval_ResNet)}, Min:{np.min(fscore_eval_ResNet)}, Max:{np.max(fscore_eval_ResNet)}\")\n",
        "plt.hist(fscore_eval_ResNet)\n",
        "plt.axvline(np.mean(fscore_eval_ResNet), color='red')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c339f14f070da8202a0a6b354db3eadd1601ac9870fe85de691374b6daa73d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
